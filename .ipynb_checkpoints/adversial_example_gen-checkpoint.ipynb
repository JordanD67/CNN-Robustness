{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc44f8d6-2a59-4b66-86b1-2ac64bfde748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jordan/miniconda3/envs/general/bin/python\n",
      "2.5.1\n",
      "/Users/jordan/miniconda3/envs/general/lib/python3.11/site-packages/torch/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "# Affiche quel Python votre notebook utilise\n",
    "print(sys.executable) \n",
    "\n",
    "# Affiche la version de PyTorch qu'il a trouvée\n",
    "print(torch.__version__) \n",
    "\n",
    "# Affiche où se trouve le fichier PyTorch\n",
    "print(torch.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8c095d0-9ee8-44da-b0a3-622ffd0042d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration initiale terminée.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. MISE EN PLACE ET IMPORTATIONS ---\n",
    "# Importations standard de Pytorch et Torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os # Ajouté pour gérer les fichiers\n",
    "\n",
    "print(\"Configuration initiale terminée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf338b2-6f8c-415d-924f-3bcd93fc4fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation du device : cpu\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Données MNIST chargées.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 2. PARAMÈTRES ET CHARGEMENT DES DONNÉES ---\n",
    "\n",
    "# Paramètres de l'attaque PGD que nous allons utiliser\n",
    "# Ce sont les \"hyperparamètres\" de notre génération de dataset\n",
    "epsilon = 0.3    # Force maximale de l'attaque\n",
    "alpha = 0.01     # Taille du pas à chaque itération\n",
    "iters = 40       # Nombre d'itérations PGD (plus c'est élevé, meilleure est l'attaque)\n",
    "\n",
    "# Définir le device (GPU si disponible)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Utilisation du device : {device}\")\n",
    "\n",
    "# Transformations pour MNIST\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "# Charger le jeu de données MNIST\n",
    "# Nous allons générer des attaques sur l'ensemble de test\n",
    "test_dataset = datasets.MNIST('../data', train=False, download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "print(\"Données MNIST chargées.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "222a96b3-7b00-44c8-81f8-501db90b4efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle victime 'mnist_cnn.pt' chargé et mis en mode évaluation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sy/c1_rq0_x6dgdg_c_vymm1lnw0000gn/T/ipykernel_37919/4212760845.py:43: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  victim_model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    }
   ],
   "source": [
    "# --- 3. CHARGER LE MODÈLE \"VICTIME\" ---\n",
    "# C'est le modèle que nous allons attaquer pour créer notre dataset.\n",
    "# Nous réutilisons le modèle simple du tutoriel PyTorch.\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "# Initialiser le modèle victime et le déplacer vers le device\n",
    "victim_model = Net().to(device)\n",
    "\n",
    "# Charger les poids pré-entraînés (fournis par le tutoriel)\n",
    "# Assurez-vous d'avoir le fichier \"mnist_cnn.pt\" dans le même dossier\n",
    "# ou de décommenter la ligne de téléchargement si vous ne l'avez pas.\n",
    "model_path = \"mnist_cnn.pt\"\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    print(\"Modèle pré-entraîné non trouvé. Téléchargement...\")\n",
    "    # Télécharger le modèle si vous ne l'avez pas\n",
    "    !wget -q https://pytorch-tutorial-assets.s3.amazonaws.com/mnist_cnn.pt\n",
    "\n",
    "victim_model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "victim_model.eval() # Mettre le modèle en mode évaluation (très important !)\n",
    "\n",
    "print(f\"Modèle victime '{model_path}' chargé et mis en mode évaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d2b74ae-0e71-4f36-824b-c7c74cbdce07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fonction d'attaque PGD définie.\n"
     ]
    }
   ],
   "source": [
    "# --- 4. DÉFINIR LA FONCTION D'ATTAQUE PGD ---\n",
    "# C'est la partie la plus importante.\n",
    "# Nous créons une attaque PGD basée sur la logique de vos documents.\n",
    "# La fonction retournera le BRUIT (delta), pas l'image attaquée.\n",
    "\n",
    "def pgd_attack(model, images, labels, eps=0.3, alpha=0.01, iters=40):\n",
    "    \n",
    "    # Cloner les images pour ne pas modifier les originales\n",
    "    images = images.clone().detach().to(device)\n",
    "    labels = labels.clone().detach().to(device)\n",
    "    \n",
    "    # Créer le tenseur de bruit (delta)\n",
    "    # Il commence à zéro et c'est lui qu'on va optimiser\n",
    "    delta = torch.zeros_like(images, requires_grad=True).to(device)\n",
    "    \n",
    "    for i in range(iters):\n",
    "        # Image perturbée\n",
    "        perturbed_image = images + delta\n",
    "        \n",
    "        # S'assurer que l'image reste dans les bornes [0, 1]\n",
    "        perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "        \n",
    "        # Passer l'image dans le modèle\n",
    "        output = model(perturbed_image)\n",
    "        loss = F.nll_loss(output, labels)\n",
    "        \n",
    "        # Calculer le gradient de la perte par rapport au bruit (delta)\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Mettre à jour le bruit (delta) en montant le gradient\n",
    "        # C'est l'étape de maximisation de la perte [cite: 474]\n",
    "        delta_update = alpha * delta.grad.detach().sign()\n",
    "        delta.data = delta.data + delta_update\n",
    "        \n",
    "        # Projeter delta pour qu'il reste dans la boule L-infini (epsilon)\n",
    "        delta.data = torch.clamp(delta.data, -eps, eps)\n",
    "        \n",
    "        # On s'assure aussi que l'image finale reste valide\n",
    "        # C'est une projection L-infini ET une projection sur [0, 1]\n",
    "        delta.data = torch.clamp(images + delta.data, 0, 1) - images\n",
    "\n",
    "    # Renvoyer uniquement le bruit\n",
    "    return delta.detach()\n",
    "\n",
    "\n",
    "print(\"Fonction d'attaque PGD définie.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb5af6f-48b2-48ff-b4e7-305fb2d09b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début de la génération du dataset. Cela peut prendre quelques minutes...\n"
     ]
    }
   ],
   "source": [
    "# --- 5. GÉNÉRER ET SAUVEGARDER LE DATASET ---\n",
    "# Nous allons maintenant boucler sur tout le test_loader\n",
    "# pour créer nos paires (image, bruit)\n",
    "\n",
    "print(\"Début de la génération du dataset. Cela peut prendre quelques minutes...\")\n",
    "\n",
    "# Listes pour stocker les tenseurs\n",
    "all_clean_images = []\n",
    "all_adversarial_noise = []\n",
    "all_labels = []\n",
    "\n",
    "# Boucle principale\n",
    "for images, labels in test_loader:\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    # Générer le bruit pour ce batch\n",
    "    noise = pgd_attack(victim_model, images, labels, eps=epsilon, alpha=alpha, iters=iters)\n",
    "    \n",
    "    # Ajouter les résultats aux listes\n",
    "    # On les déplace sur CPU pour libérer la mémoire GPU\n",
    "    all_clean_images.append(images.cpu())\n",
    "    all_adversarial_noise.append(noise.cpu())\n",
    "    all_labels.append(labels.cpu())\n",
    "\n",
    "# Concaténer tous les batches en deux grands tenseurs\n",
    "clean_images_tensor = torch.cat(all_clean_images, dim=0)\n",
    "noise_tensor = torch.cat(all_adversarial_noise, dim=0)\n",
    "labels_tensor = torch.cat(all_labels, dim=0)\n",
    "\n",
    "print(f\"Génération terminée. Tenseurs créés :\")\n",
    "print(f\"Images (X): {clean_images_tensor.shape}\")\n",
    "print(f\"Bruit (Y):  {noise_tensor.shape}\")\n",
    "print(f\"Labels:     {labels_tensor.shape}\")\n",
    "\n",
    "\n",
    "# Sauvegarder les tenseurs sur le disque\n",
    "torch.save(clean_images_tensor, 'dataset_clean_images.pt')\n",
    "torch.save(noise_tensor, 'dataset_adv_noise.pt')\n",
    "torch.save(labels_tensor, 'dataset_labels.pt')\n",
    "\n",
    "print(\"Dataset sauvegardé ! Fichiers créés :\")\n",
    "print(\"- dataset_clean_images.pt (Les X de votre générateur)\")\n",
    "print(\"- dataset_adv_noise.pt (Les Y, 'ground truth', de votre générateur)\")\n",
    "print(\"- dataset_labels.pt (Utile pour vérifier les attaques)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9532e737-81c9-4c83-aaf6-b68e3d997df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. VÉRIFICATION (Optionnel mais recommandé) ---\n",
    "\n",
    "print(\"\\nVérification d'un échantillon...\")\n",
    "\n",
    "# Prendre 5 images au hasard\n",
    "indices = np.random.choice(len(clean_images_tensor), 5, replace=False)\n",
    "sample_images = clean_images_tensor[indices].to(device)\n",
    "sample_noise = noise_tensor[indices].to(device)\n",
    "sample_labels = labels_tensor[indices].to(device)\n",
    "\n",
    "# Créer les images adverses en ajoutant le bruit\n",
    "adv_images = torch.clamp(sample_images + sample_noise, 0, 1)\n",
    "\n",
    "# Obtenir les prédictions\n",
    "with torch.no_grad():\n",
    "    pred_clean = victim_model(sample_images).argmax(dim=1)\n",
    "    pred_adv = victim_model(adv_images).argmax(dim=1)\n",
    "\n",
    "# Afficher les résultats\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 10))\n",
    "fig.suptitle(f\"Vérification : Attaque PGD (eps={epsilon})\", fontsize=16)\n",
    "\n",
    "for i in range(5):\n",
    "    # Image originale\n",
    "    axes[0, i].imshow(sample_images[i].cpu().squeeze(), cmap=\"gray\")\n",
    "    axes[0, i].set_title(f\"Originale\\nLabel: {sample_labels[i].item()}\\nPred: {pred_clean[i].item()}\",\n",
    "                         color=(\"green\" if pred_clean[i] == sample_labels[i] else \"red\"))\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    # Bruit (le \"Y\" de votre futur modèle)\n",
    "    # On normalise le bruit pour l'afficher, sinon il est quasi invisible\n",
    "    noise_viz = (sample_noise[i].cpu().squeeze() - sample_noise[i].min()) / (sample_noise[i].max() - sample_noise[i].min())\n",
    "    axes[1, i].imshow(noise_viz, cmap=\"coolwarm\")\n",
    "    axes[1, i].set_title(\"Bruit (Y)\\n(visualisation normalisée)\")\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "    # Image adverse\n",
    "    axes[2, i].imshow(adv_images[i].cpu().squeeze(), cmap=\"gray\")\n",
    "    axes[2, i].set_title(f\"Adverse\\nLabel: {sample_labels[i].item()}\\nPred: {pred_adv[i].item()}\",\n",
    "                         color=(\"red\" if pred_adv[i] != sample_labels[i] else \"green\"))\n",
    "    axes[2, i].axis('off')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- FIN DU NOTEBOOK ---\")\n",
    "print(\"Vous avez maintenant les fichiers pour entraîner votre générateur d'attaques.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
